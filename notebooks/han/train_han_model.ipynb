{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train HAN Model for Sepsis Prediction\n",
    "\n",
    "**Input**: HeteroData from `owl_to_heterodata.ipynb`  \n",
    "**Output**: Trained HAN model with attention weights\n",
    "\n",
    "**HAN** (Heterogeneous Attention Network) uses:\n",
    "- **Node-level attention**: Which neighbors are important?\n",
    "- **Semantic-level attention**: Which metapaths are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root: /Users/silviatrottet/Documents/M2_GENIOMHE/Deep Learning/2526-m2geniomhe-GNN-sepsis\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import HANConv  # Use HANConv layer\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "print(f\"✓ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading HeteroData from: hetero_graph_han.pt\n",
      "\n",
      "HeteroData(\n",
      "  patient={\n",
      "    x=[163, 163],\n",
      "    y=[163],\n",
      "    train_mask=[163],\n",
      "    val_mask=[163],\n",
      "    test_mask=[163],\n",
      "  },\n",
      "  protein={ x=[1295, 1295] },\n",
      "  (patient, expresses, protein)={ edge_index=[2, 277784] },\n",
      "  (protein, interacts, protein)={ edge_index=[2, 2821] }\n",
      ")\n",
      "\n",
      "Node types: ['patient', 'protein']\n",
      "Edge types: [('patient', 'expresses', 'protein'), ('protein', 'interacts', 'protein')]\n"
     ]
    }
   ],
   "source": [
    "data_path = project_root / \"data\" / \"han\" / \"hetero_graph_han.pt\"\n",
    "\n",
    "print(f\"Loading HeteroData from: {data_path.name}\")\n",
    "data = torch.load(data_path, weights_only=False)  # PyTorch 2.6+ requires this\n",
    "\n",
    "print(f\"\\n{data}\")\n",
    "print(f\"\\nNode types: {data.node_types}\")\n",
    "print(f\"Edge types: {data.edge_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Metapaths\n",
    "\n",
    "**Metapaths** = paths through the graph that capture different semantic relationships\n",
    "\n",
    "For our sepsis prediction:\n",
    "- `Patient → Protein → Patient`: Patients connected through shared proteins\n",
    "- `Patient → Protein → Protein → Patient`: Patients connected through interacting proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metapaths for HAN\n",
    "metapaths = [\n",
    "    # Metapath 1: Patient → expresses → Protein → rev_expresses → Patient\n",
    "    [('patient', 'expresses', 'protein'), ('protein', 'rev_expresses', 'patient')],\n",
    "    \n",
    "    # Metapath 2: Patient → expresses → Protein → interacts → Protein → rev_expresses → Patient\n",
    "    [('patient', 'expresses', 'protein'), \n",
    "     ('protein', 'interacts', 'protein'),\n",
    "     ('protein', 'rev_expresses', 'patient')]\n",
    "]\n",
    "\n",
    "print(\"Metapaths defined:\")\n",
    "for i, mp in enumerate(metapaths, 1):\n",
    "    path_str = ' → '.join([f\"{s}--[{r}]--{d}\" for s, r, d in mp])\n",
    "    print(f\"  {i}. {path_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Reverse Edges\n",
    "\n",
    "HAN needs reverse edges for metapaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add reverse edges for patient→protein\n",
    "edge_index = data['patient', 'expresses', 'protein'].edge_index\n",
    "data['protein', 'rev_expresses', 'patient'].edge_index = edge_index.flip(0)\n",
    "\n",
    "print(f\"✓ Added reverse edges\")\n",
    "print(f\"\\nUpdated edge types: {data.edge_types}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create HAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HANClassifier(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    HAN-based classifier for sepsis prediction using HANConv layers\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, metadata, num_heads=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        # HANConv layer\n",
    "        self.han_conv = HANConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            metadata=metadata,\n",
    "            heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # Classifier for patient nodes\n",
    "        self.classifier = torch.nn.Linear(hidden_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        # HANConv forward pass\n",
    "        out_dict = self.han_conv(x_dict, edge_index_dict)\n",
    "        \n",
    "        # Classify patient nodes\n",
    "        patient_out = self.classifier(out_dict['patient'])\n",
    "        \n",
    "        return patient_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "in_channels = -1  # Auto-infer from data\n",
    "hidden_channels = 64\n",
    "out_channels = 2  # Binary: sepsis vs healthy\n",
    "num_heads = 8\n",
    "\n",
    "# Create model\n",
    "model = HANClassifier(\n",
    "    in_channels=in_channels,\n",
    "    hidden_channels=hidden_channels,\n",
    "    out_channels=out_channels,\n",
    "    metadata=data.metadata(),\n",
    "    num_heads=num_heads\n",
    ")\n",
    "\n",
    "# Initialize lazy modules with a dummy forward pass\n",
    "with torch.no_grad():\n",
    "    _ = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "print(f\"✓ Model created and initialized\")\n",
    "print(f\"\\nParameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set class distribution:\n",
      "  Class 0 (healthy): 22\n",
      "  Class 1 (sepsis):  92\n",
      "  Ratio: 0.24:1\n",
      "\n",
      "Class weights (computed automatically):\n",
      "  Class 0: 2.5909\n",
      "  Class 1: 0.6196\n",
      "\n",
      "✓ Optimizer: Adam (lr=0.001)\n",
      "✓ Loss: CrossEntropyLoss with class weights\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights to handle imbalance\n",
    "y_train = data['patient'].y[data['patient'].train_mask]\n",
    "n_class_0 = (y_train == 0).sum().item()\n",
    "n_class_1 = (y_train == 1).sum().item()\n",
    "total = n_class_0 + n_class_1\n",
    "\n",
    "# Calculate inverse frequency weights automatically\n",
    "weight_class_0 = total / (2 * n_class_0)\n",
    "weight_class_1 = total / (2 * n_class_1)\n",
    "class_weights = torch.tensor([weight_class_0, weight_class_1], dtype=torch.float)\n",
    "\n",
    "print(f\"Training set class distribution:\")\n",
    "print(f\"  Class 0 (healthy): {n_class_0}\")\n",
    "print(f\"  Class 1 (sepsis):  {n_class_1}\")\n",
    "print(f\"  Ratio: {n_class_0 / n_class_1:.2f}:1\")\n",
    "print(f\"\\nClass weights (computed automatically):\")\n",
    "print(f\"  Class 0: {weight_class_0:.4f}\")\n",
    "print(f\"  Class 1: {weight_class_1:.4f}\")\n",
    "\n",
    "# Optimizer and loss with class weights\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "print(\"\\n✓ Optimizer: Adam (lr=0.001)\")\n",
    "print(\"✓ Loss: CrossEntropyLoss with class weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    \n",
    "    # Loss on training nodes only\n",
    "    loss = criterion(out[data['patient'].train_mask], \n",
    "                     data['patient'].y[data['patient'].train_mask])\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(mask):\n",
    "    model.eval()\n",
    "    \n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct = (pred[mask] == data['patient'].y[mask]).sum()\n",
    "    acc = int(correct) / int(mask.sum())\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HAN...\n",
      "\n",
      "Epoch | Train Loss | Val Acc | Test Acc\n",
      "---------------------------------------------\n",
      "  10  | 0.6863     | 0.875   | 0.680\n",
      "  20  | 0.6854     | 0.917   | 0.880\n",
      "  30  | 0.6845     | 0.958   | 0.920\n",
      "  40  | 0.6834     | 0.917   | 0.800\n",
      "  50  | 0.6821     | 0.917   | 0.760\n",
      "  60  | 0.6807     | 0.917   | 0.800\n",
      "  70  | 0.6789     | 0.917   | 0.800\n",
      "  80  | 0.6768     | 0.917   | 0.800\n",
      "  90  | 0.6740     | 0.917   | 0.800\n",
      " 100  | 0.6704     | 0.917   | 0.840\n",
      " 110  | 0.6654     | 0.917   | 0.840\n",
      " 120  | 0.6584     | 0.958   | 0.880\n",
      " 130  | 0.6478     | 0.958   | 0.920\n",
      " 140  | 0.6315     | 0.958   | 0.920\n",
      " 150  | 0.6065     | 0.958   | 0.880\n",
      " 160  | 0.5695     | 0.958   | 0.920\n",
      " 170  | 0.5172     | 0.750   | 0.840\n",
      " 180  | 0.4499     | 0.667   | 0.840\n",
      " 190  | 0.3728     | 0.667   | 0.840\n",
      " 200  | 0.2973     | 0.625   | 0.800\n",
      "\n",
      " Best validation accuracy: 0.958\n"
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "num_epochs = 200\n",
    "patience = 20\n",
    "best_val_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Training HAN...\\n\")\n",
    "print(f\"Epoch | Train Loss | Val Acc | Test Acc\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        val_acc = evaluate(data['patient'].val_mask)\n",
    "        test_acc = evaluate(data['patient'].test_mask)\n",
    "        \n",
    "        print(f\"{epoch:4d}  | {loss:.4f}     | {val_acc:.3f}   | {test_acc:.3f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), project_root / 'best_han_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\n Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "print(f\"\\n Best validation accuracy: {best_val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Final Results\n",
      "==================================================\n",
      "Train Accuracy: 97.4%\n",
      "Val Accuracy:   95.8%\n",
      "Test Accuracy:  92.0%\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(project_root / 'best_han_model.pt', weights_only=False))\n",
    "\n",
    "# Evaluate\n",
    "train_acc = evaluate(data['patient'].train_mask)\n",
    "val_acc = evaluate(data['patient'].val_mask)\n",
    "test_acc = evaluate(data['patient'].test_mask)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Final Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Train Accuracy: {train_acc:.1%}\")\n",
    "print(f\"Val Accuracy:   {val_acc:.1%}\")\n",
    "print(f\"Test Accuracy:  {test_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Attention Weights\n",
    "\n",
    "Get node-level and semantic-level attention for interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Attention weights computed\n",
      "\n",
      "Next: Extract and visualize attention for specific patients\n"
     ]
    }
   ],
   "source": [
    "# Get attention weights from HAN\n",
    "model.eval()\n",
    "\n",
    "# Forward pass to get embeddings and attentions\n",
    "with torch.no_grad():\n",
    "    out = model(data.x_dict, data.edge_index_dict)\n",
    "\n",
    "print(\"✓ Attention weights computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model saved to: /Users/silviatrottet/Documents/M2_GENIOMHE/Deep Learning/2526-m2geniomhe-GNN-sepsis/results/han/han_model.pt\n"
     ]
    }
   ],
   "source": [
    "# Save complete model info\n",
    "output_path = project_root / \"results\" / \"han\" / \"han_model.pt\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'train_acc': train_acc,\n",
    "    'val_acc': val_acc,\n",
    "    'test_acc': test_acc,\n",
    "    'hidden_channels': hidden_channels,\n",
    "    'num_heads': num_heads\n",
    "}, output_path)\n",
    "\n",
    "print(f\"\\n Model saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_han (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
